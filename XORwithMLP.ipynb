{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XORwithMLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrU0nEmOqYBNRP4YSJfRSj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/technologyhamed/MultilayerPerceptronNeuralNetwork/blob/main/XORwithMLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3cx0XV-NwqZ",
        "outputId": "6eb0e65e-5d92-4385-cae1-6a82281d4ff2"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.random.seed(0)\n",
        "\n",
        "def generate_zero():\n",
        "    return random.uniform(0, 49) / 100\n",
        "\n",
        "def generate_one():\n",
        "    return random.uniform(50, 100) / 100\n",
        "\n",
        "\n",
        "def generate_xor_XY(num_data_points):\n",
        "    Xs, Ys = [], []\n",
        "    for _ in range(num_data_points):\n",
        "        # xor(0, 0) -> 0 \n",
        "        Xs.append([generate_zero(), generate_zero()]); Ys.append([0])\n",
        "        # xor(1, 0) -> 1\n",
        "        Xs.append([generate_one(), generate_zero()]); Ys.append([1])\n",
        "        # xor(0, 1) -> 1\n",
        "        Xs.append([generate_zero(), generate_one()]); Ys.append([1])\n",
        "        # xor(1, 1) -> 0\n",
        "        Xs.append([generate_one(), generate_one()]); Ys.append([0])\n",
        "    return Xs, Ys\n",
        "\n",
        "\n",
        "def generate_or_XY(num_data_points):\n",
        "    Xs, Ys = [], []\n",
        "    for _ in range(num_data_points):\n",
        "        # xor(0, 0) -> 0 \n",
        "        Xs.append([generate_zero(), generate_zero()]); Ys.append([0])\n",
        "        # xor(0, 1) -> 1\n",
        "        Xs.append([generate_zero(), generate_one()]); Ys.append([1])\n",
        "        # xor(1, 0) -> 1\n",
        "        Xs.append([generate_one(), generate_zero()]); Ys.append([1])\n",
        "        # xor(1, 1) -> 0\n",
        "        Xs.append([generate_one(), generate_one()]); Ys.append([1])\n",
        "    return Xs, Ys\n",
        "\n",
        "X, Y = generate_or_XY(100)\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# First 20 instance of new data.\n",
        "for i, (x, y) in enumerate(zip(X, Y)):\n",
        "    if i > 20:\n",
        "        break\n",
        "    print(x, [int(_x > 0.5) for _x in x],  y)\n",
        "\n",
        "def sigmoid(x): # Returns values that sums to one.\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(sx):\n",
        "    # See https://math.stackexchange.com/a/1225116\n",
        "    return sx * (1 - sx)\n",
        "\n",
        "# Cost functions.\n",
        "def cost(predicted, truth):\n",
        "    return truth - predicted\n",
        "\n",
        "# Shuffle the order of the inputs\n",
        "_temp = list(zip(X, Y))\n",
        "random.shuffle(_temp)\n",
        "xor_input_shuff, xor_output_shuff = map(np.array, zip(*_temp))\n",
        "\n",
        "# Lets split the data to 90-10. \n",
        "train_split = int(len(X) / 100 * 90)\n",
        "X_train = xor_input_shuff[:train_split]\n",
        "Y_train = xor_output_shuff[:train_split]\n",
        "\n",
        "X_test = xor_input_shuff[train_split:]\n",
        "Y_test = xor_output_shuff[train_split:]\n",
        "\n",
        "# Define the shape of the weight vector.\n",
        "num_data, input_dim = X_train.shape\n",
        "# Lets set the dimensions for the intermediate layer.\n",
        "hidden_dim = 5\n",
        "# Initialize weights between the input layers and the hidden layer.\n",
        "W1 = np.random.random((input_dim, hidden_dim))\n",
        "\n",
        "# Define the shape of the output vector. \n",
        "output_dim = len(Y_train.T)\n",
        "# Initialize weights between the hidden layers and the output layer.\n",
        "W2 = np.random.random((hidden_dim, output_dim))\n",
        "\n",
        "num_epochs = 2000\n",
        "learning_rate = 0.03\n",
        "\n",
        "for epoch_n in range(num_epochs):\n",
        "    layer0 = X_train\n",
        "    # Forward propagation.\n",
        "    \n",
        "    # Inside the perceptron, Step 2. \n",
        "    layer1 = sigmoid(np.dot(layer0, W1))\n",
        "    layer2 = sigmoid(np.dot(layer1, W2))\n",
        "\n",
        "    # Back propagation (Y -> layer2)\n",
        "    \n",
        "    # How much did we miss in the predictions?\n",
        "    layer2_error = cost(layer2, Y_train)\n",
        "    # In what direction is the target value?\n",
        "    # Were we really close? If so, don't change too much.\n",
        "    layer2_delta = layer2_error * sigmoid_derivative(layer2)\n",
        "\n",
        "    \n",
        "    # Back propagation (layer2 -> layer1)\n",
        "    # How much did each layer1 value contribute to the layer2 error (according to the weights)?\n",
        "    layer1_error = np.dot(layer2_delta, W2.T)\n",
        "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
        "    \n",
        "    # update weights\n",
        "    W2 +=  learning_rate * np.dot(layer1.T, layer2_delta)\n",
        "    W1 +=  learning_rate * np.dot(layer0.T, layer1_delta)\n",
        "    accurate = 0\n",
        "for x, y in zip(X_test, Y_test):\n",
        "    layer1_prediction = sigmoid(np.dot(W1.T, x)) # Feed the unseen input into trained W.\n",
        "    prediction = layer2_prediction = sigmoid(np.dot(W2.T, layer1_prediction)) # Feed the unseen input into trained W.\n",
        "    print(x, [int(_x > 0.5) for _x in x], int(prediction > 0.5), y)\n",
        "    accurate += int(prediction > 0.5) == y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.29490791 0.10789841] [0, 0] [0]\n",
            "[0.05948712 0.99198372] [0, 1] [1]\n",
            "[0.94800888 0.27969585] [1, 0] [1]\n",
            "[0.52331741 0.6007686 ] [1, 1] [1]\n",
            "[0.05617461 0.22500383] [0, 0] [0]\n",
            "[0.35950006 0.66934478] [0, 1] [1]\n",
            "[0.63635241 0.33575989] [1, 0] [1]\n",
            "[0.78910463 0.69927793] [1, 1] [1]\n",
            "[0.34685912 0.25650646] [0, 0] [0]\n",
            "[0.03698042 0.91382323] [0, 1] [1]\n",
            "[0.64848865 0.39308694] [1, 0] [1]\n",
            "[0.77343155 0.82217914] [1, 1] [1]\n",
            "[0.39165814 0.37936566] [0, 0] [0]\n",
            "[0.23471025 0.68221182] [0, 1] [1]\n",
            "[0.86151304 0.05569874] [1, 0] [1]\n",
            "[0.50904611 0.52060759] [1, 1] [1]\n",
            "[0.32368373 0.45410578] [0, 0] [0]\n",
            "[0.36540301 0.58067859] [0, 1] [1]\n",
            "[0.73751326 0.43165459] [1, 0] [1]\n",
            "[0.69424455 0.98780581] [1, 1] [1]\n",
            "[0.42083628 0.41630809] [0, 0] [0]\n",
            "[0.67262045 0.02291332] [1, 0] 1 [1]\n",
            "[0.02544945 0.74414793] [0, 1] 1 [1]\n",
            "[0.32016211 0.61377301] [0, 1] 1 [1]\n",
            "[0.28864266 0.63393742] [0, 1] 1 [1]\n",
            "[0.06562944 0.36989934] [0, 0] 0 [0]\n",
            "[0.18550277 0.00865731] [0, 0] 0 [0]\n",
            "[0.0028398 0.9276141] [0, 1] 1 [1]\n",
            "[0.96907738 0.91848855] [1, 1] 1 [1]\n",
            "[0.20280336 0.40848043] [0, 0] 0 [0]\n",
            "[0.23471025 0.68221182] [0, 1] 1 [1]\n",
            "[0.87185981 0.45293664] [1, 0] 1 [1]\n",
            "[0.41296478 0.94468503] [0, 1] 1 [1]\n",
            "[0.42345819 0.73666141] [0, 1] 1 [1]\n",
            "[0.34614907 0.76173034] [0, 1] 1 [1]\n",
            "[0.34937608 0.4510022 ] [0, 0] 1 [0]\n",
            "[0.87490362 0.15136518] [1, 0] 1 [1]\n",
            "[0.63786511 0.13206139] [1, 0] 1 [1]\n",
            "[0.50517753 0.08545552] [1, 0] 0 [1]\n",
            "[0.98747189 0.55513361] [1, 1] 1 [1]\n",
            "[0.84169694 0.80240927] [1, 1] 1 [1]\n",
            "[0.79298202 0.77786933] [1, 1] 1 [1]\n",
            "[0.96541454 0.14249314] [1, 0] 1 [1]\n",
            "[0.90444207 0.97473696] [1, 1] 1 [1]\n",
            "[0.31584933 0.69206652] [0, 1] 1 [1]\n",
            "[0.29244652 0.81620778] [0, 1] 1 [1]\n",
            "[0.11298596 0.71907416] [0, 1] 1 [1]\n",
            "[0.95832283 0.2168537 ] [1, 0] 1 [1]\n",
            "[0.54628063 0.20560322] [1, 0] 1 [1]\n",
            "[0.86796821 0.78181156] [1, 1] 1 [1]\n",
            "[0.00607103 0.45214462] [0, 0] 0 [0]\n",
            "[0.47783061 0.41768836] [0, 0] 1 [0]\n",
            "[0.63471642 0.51946274] [1, 1] 1 [1]\n",
            "[0.47889773 0.03003881] [0, 0] 0 [0]\n",
            "[0.89350297 0.83812812] [1, 1] 1 [1]\n",
            "[0.52032618 0.59132384] [1, 1] 1 [1]\n",
            "[0.67612172 0.52775646] [1, 1] 1 [1]\n",
            "[0.27853817 0.00629776] [0, 0] 0 [0]\n",
            "[0.72584027 0.77568608] [1, 1] 1 [1]\n",
            "[0.50241462 0.45391603] [1, 0] 1 [1]\n",
            "[0.54814164 0.12024951] [1, 0] 1 [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYUWSpvBPd5x",
        "outputId": "6b546cc3-7d3e-42e7-a2ca-aab671e85b35"
      },
      "source": [
        "print(accurate/len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.925]\n"
          ]
        }
      ]
    }
  ]
}